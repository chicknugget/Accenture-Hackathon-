{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc308496-0439-4c20-b91a-dcf2f0599603",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shrey\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55dbc5be-150f-4b34-95e2-5c2f29e92559",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae26ad3-4e43-459a-8316-db2cb04b74e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Result:\n",
      "--------------------------------------------------\n",
      "Predicted Issue Type:  Technical Support\n",
      "Predicted Sentiment:   Anxious\n",
      "Predicted Priority:    High\n",
      "\n",
      "Recommended Solutions:\n",
      "1. Hi there! Let’s resolve this together. Are both devices logged into the same account? Could you share the sync logs? Thanks for sharing! The log shows a corrupted sync token. I’ll reset it manually. Go to Settings > Sync > Force Full Sync and wait 10 minutes. Let me know if it works! Great news! A patch releasing next week will prevent this issue. Thanks for your patience!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import download\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "download('punkt')\n",
    "download('stopwords')\n",
    "download('wordnet')\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and short tokens\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and len(token) > 1]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Parse Conversation Files Function\n",
    "def parse_conversation(content):\n",
    "    # Extract metadata using regex\n",
    "    conv_id_match = re.search(r'Conversation ID: (.+)', content)\n",
    "    category_match = re.search(r'Category: (.+)', content)\n",
    "    sentiment_match = re.search(r'Sentiment: ([^|]+)', content)\n",
    "    priority_match = re.search(r'Priority: (.+)', content)\n",
    "    \n",
    "    # Extract customer and agent messages\n",
    "    customer_messages = re.findall(r'Customer: \"(.+?)\"', content)\n",
    "    agent_messages = re.findall(r'Agent: \"(.+?)\"', content)\n",
    "    \n",
    "    conversation_text = ' '.join(customer_messages + agent_messages)\n",
    "    \n",
    "    return {\n",
    "        'Conversation ID': conv_id_match.group(1).strip() if conv_id_match else None,\n",
    "        'Category': category_match.group(1).strip() if category_match else None,\n",
    "        'Sentiment': sentiment_match.group(1).strip() if sentiment_match else None,\n",
    "        'Priority': priority_match.group(1).strip() if priority_match else None,\n",
    "        'Customer Text': ' '.join(customer_messages),\n",
    "        'Agent Text': ' '.join(agent_messages),\n",
    "        'Full Text': conversation_text\n",
    "    }\n",
    "\n",
    "# Load Conversation Files Content\n",
    "conversation_files_content = [\n",
    "    \"\"\"Conversation ID: TECH_003\n",
    "Category: Technical Support\n",
    "Sentiment: Annoyed | Priority: Critical\n",
    "Customer: \"Hi, I’m really frustrated. Your smart home app crashes every time I try to connect my older thermostat model. It worked fine on my old phone!\"\n",
    "Agent: \"Hello! I apologize for the trouble. Could you confirm your phone model and app version?\"\n",
    "Customer: \"iPhone 15, app version 5.2.1. The thermostat is Model HT-2019.\"\n",
    "Agent: \"Thank you for clarifying. Unfortunately, HT-2019 isn’t supported in versions after 5.0. We can roll back your app to 4.9 or offer a discount on a compatible thermostat. What works best for you?\"\n",
    "Customer: \"I’ll take the discount, but this is disappointing.\"\n",
    "Agent: \"Understood. I’ll email the discount code shortly. We appreciate your patience!\"\n",
    "\"\"\",\n",
    "    \"\"\"Conversation ID: TECH_002\n",
    "Category: Technical Support\n",
    "Sentiment: Confused | Priority: Medium\n",
    "Customer: \"Good morning! I’m having an issue where my app keeps saying ‘no internet connection,’ but my Wi-Fi is working fine. Other apps load normally.\"\n",
    "Agent: \"Hi! Thanks for contacting us. Let’s check the app’s network permissions. Go to Settings > Apps > [App Name] > Permissions. Is ‘Local Network’ enabled?\"\n",
    "Customer: \"Hmm, it was off! I just turned it on, but still no luck.\"\n",
    "Agent: \"No worries! Please clear the app cache: Settings > Storage > Clear Cache. Then log in again. Does that help?\"\n",
    "Customer: \"That fixed it! Thank you! Any idea why this happened suddenly?\"\n",
    "Agent: \"Glad to hear it! A recent update may have reset permissions. We’ll flag this to our dev team. Cheers!\"\n",
    "\"\"\",\n",
    "    \"\"\"Conversation ID: TECH_001\n",
    "Category: Technical Support\n",
    "Sentiment: Frustrated | Priority: High\n",
    "Customer: \"Hi there! I’ve been trying to install the latest update for your design software for hours. It keeps failing at 75% with an ‘unknown error.’ What’s wrong?\"\n",
    "Agent: \"Hello! Thank you for reaching out. Let me help troubleshoot. Could you share a screenshot of the error message and confirm your operating system version?\"\n",
    "Customer: \"Sure, it’s Windows 11. Here’s the screenshot: [image link]. I’ve restarted twice, same issue.\"\n",
    "Agent: \"Thank you for the details. This is a known conflict with third-party antivirus tools. Could you temporarily disable your antivirus and retry? I’ll also send a direct download link as a workaround.\"\n",
    "Customer: \"Oh, disabling the antivirus worked! Installation completed. Thanks for your help!\"\n",
    "Agent: \"You’re welcome! Let us know if you need further assistance. Have a great day!\"\n",
    "\"\"\",\n",
    "    \"\"\"Conversation ID: TECH_005\n",
    "Category: Technical Support\n",
    "Sentiment: Urgent | Priority: Critical\n",
    "Customer: \"Hi, this is urgent! Your API is rejecting our payment gateway integration. Error: ‘Invalid SSL certificate.’ Our cert is valid and up-to-date!\"\n",
    "Agent: \"Hello! Let’s investigate immediately. Could you share the output from openssl s_client -connect yourgateway.com:443?\"\n",
    "Customer: \"Here’s the terminal output: [text]. See? No errors here.\"\n",
    "Agent: \"Thank you! Our system requires TLS 1.3, but your server supports only up to TLS 1.2. Upgrading the protocol will resolve the authentication error.\"\n",
    "Customer: \"Upgrading worked! Thanks for the quick fix!\"\n",
    "Agent: \"Happy to help! Don’t hesitate to reach out for future issues. Goodbye!\"\n",
    "\"\"\",\n",
    "    \"\"\"Conversation ID: TECH_004\n",
    "Category: Technical Support\n",
    "Sentiment: Anxious | Priority: High\n",
    "Customer: \"Hello! My project data isn’t syncing between my laptop and tablet. Changes on one device don’t show up on the other. Can you help?\"\n",
    "Agent: \"Hi there! Let’s resolve this together. Are both devices logged into the same account? Could you share the sync logs?\"\n",
    "Customer: \"Yes, same account. Here’s a log from my tablet: [file attached].\"\n",
    "Agent: \"Thanks for sharing! The log shows a corrupted sync token. I’ll reset it manually. Go to Settings > Sync > Force Full Sync and wait 10 minutes. Let me know if it works!\"\n",
    "Customer: \"It’s syncing now! Will this happen again?\"\n",
    "Agent: \"Great news! A patch releasing next week will prevent this issue. Thanks for your patience!\"\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "# Parse Conversations into a DataFrame\n",
    "conversations_data = []\n",
    "for content in conversation_files_content:\n",
    "    parsed_data = parse_conversation(content)\n",
    "    conversations_data.append(parsed_data)\n",
    "\n",
    "conversations_df = pd.DataFrame(conversations_data)\n",
    "\n",
    "# Load Historical Ticket Data from CSV\n",
    "historical_data = pd.read_csv('Historical_ticket_data.csv')\n",
    "\n",
    "# Clean column names in historical data\n",
    "historical_data.columns = historical_data.columns.str.strip()\n",
    "\n",
    "# Preprocess Text Data\n",
    "conversations_df['Preprocessed_Customer_Text'] = conversations_df['Customer Text'].apply(preprocess_text)\n",
    "\n",
    "# Extract Features Using TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(conversations_df['Preprocessed_Customer_Text'])\n",
    "\n",
    "# Train Classifiers for Issue Type, Sentiment, and Priority Prediction\n",
    "X = tfidf_features\n",
    "y_issue_type = conversations_df['Category']\n",
    "y_sentiment = conversations_df['Sentiment']\n",
    "y_priority = conversations_df['Priority']\n",
    "\n",
    "issue_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "issue_classifier.fit(X, y_issue_type)\n",
    "\n",
    "sentiment_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "sentiment_classifier.fit(X, y_sentiment)\n",
    "\n",
    "priority_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "priority_classifier.fit(X, y_priority)\n",
    "\n",
    "# Create Solution Mapping from Historical Data and Conversations Data\n",
    "issue_solution_mapping = {}\n",
    "\n",
    "# Populate solution mapping from historical data\n",
    "for _, row in historical_data.iterrows():\n",
    "    key = (row['Issue Category'], row['Sentiment'], row['Priority'])\n",
    "    solution_texts = row['Solution']\n",
    "    \n",
    "    if key in issue_solution_mapping:\n",
    "        if isinstance(solution_texts, str):\n",
    "            issue_solution_mapping[key].append(solution_texts)\n",
    "        elif isinstance(solution_texts, list):\n",
    "            issue_solution_mapping[key].extend(solution_texts)\n",
    "        else:\n",
    "            issue_solution_mapping[key].append(str(solution_texts))\n",
    "    else:\n",
    "        issue_solution_mapping[key] = [solution_texts]\n",
    "\n",
    "# Populate solution mapping from conversation data\n",
    "for _, row in conversations_df.iterrows():\n",
    "    key = (row['Category'], row['Sentiment'], row['Priority'])\n",
    "    solution_texts = row['Agent Text']\n",
    "    \n",
    "    if key in issue_solution_mapping:\n",
    "        if isinstance(solution_texts, str):\n",
    "            issue_solution_mapping[key].append(solution_texts)\n",
    "        elif isinstance(solution_texts, list):\n",
    "            issue_solution_mapping[key].extend(solution_texts)\n",
    "        else:\n",
    "            issue_solution_mapping[key].append(str(solution_texts))\n",
    "    else:\n",
    "        issue_solution_mapping[key] = [solution_texts]\n",
    "\n",
    "# Analyze New Customer Text Function\n",
    "def analyze_text_nlp(text, issue_clf, sentiment_clf, priority_clf, vectorizer, solution_mapping):\n",
    "    # Preprocess the input text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    \n",
    "    # Vectorize the text using TF-IDF vectorizer\n",
    "    features = vectorizer.transform([preprocessed_text])\n",
    "    \n",
    "    # Predict issue type, sentiment, and priority using classifiers\n",
    "    predicted_issue_type = issue_clf.predict(features)[0]\n",
    "    predicted_sentiment = sentiment_clf.predict(features)[0]\n",
    "    predicted_priority = priority_clf.predict(features)[0]\n",
    "    \n",
    "    # Find solutions based on predictions\n",
    "    key = (predicted_issue_type, predicted_sentiment, predicted_priority)\n",
    "    solutions = solution_mapping.get(key, [\"No matching solution found.\"])\n",
    "    \n",
    "    return predicted_issue_type, predicted_sentiment, predicted_priority, solutions\n",
    "\n",
    "# Example Usage of the System with a New Inquiry Text\n",
    "new_customer_inquiry = \"The app is running very slow. It takes forever to load. It is so frustrating.\" #\"The app is running very slow. It takes forever to load. It is so frustrating.\"\n",
    "predicted_issue_type, predicted_sentiment, predicted_priority, recommended_solutions = analyze_text_nlp(\n",
    "    new_customer_inquiry,\n",
    "    issue_classifier,\n",
    "    sentiment_classifier,\n",
    "    priority_classifier,\n",
    "    tfidf_vectorizer,\n",
    "    issue_solution_mapping\n",
    ")\n",
    "\n",
    "print(\"Analysis Result:\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(f\"Predicted Issue Type:  {predicted_issue_type}\")\n",
    "print(f\"Predicted Sentiment:   {predicted_sentiment}\")\n",
    "print(f\"Predicted Priority:    {predicted_priority}\")\n",
    "print(\"\\nRecommended Solutions:\")\n",
    "if recommended_solutions:\n",
    "    for i, solution in enumerate(recommended_solutions, 1):\n",
    "        print(f\"{i}. {solution}\")\n",
    "else:\n",
    "    print(\"No matching solution found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1e6c1-ffbe-4309-a71f-f39cb60dcdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpenv",
   "language": "python",
   "name": "mpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
